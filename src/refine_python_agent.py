import json
from pathlib import Path
from typing import Dict, List, Tuple
import argparse
import os
from datetime import datetime
import ast
import json
from typing import Dict
import utils.python_call as py
from llama_index.core.base.llms.types import ChatMessage, MessageRole
from check_consistency import ConsistencyChecker
from utils.gen_config import get_llm
from utils.log_utils import get_logger
from utils.prompts import ORDER_PROMPT
from utils.token_counter import TokenCounter, TokenCounterCached
from utils.gen_config import Config
from utils.log_utils import get_logger, set_log_dir, switch_log_to_file
logger = get_logger(__name__)

SYSTEM_PROMPT = r"""
You are an expert in RTL and python code.
Your task is to review a natural-language RTL specification, a python code that realize the function described in the specification, and a report from another judge agent if there are mismatches of the testbench generated by the python code.
You must think about how to refine the python code according to the report to realize the real function described in the specification. Please note that you can only refine the python function node, not the function interface and the return value.

"""

INIT_EDITION_PROMPT = """
First, carefully read the following RTL specification:

<specification>
{specification}
</specification>

Now, read the Python code that attempts to implement this specification:

<python_code>
{python_code}
</python_code>

Next, review the report from another judge agent that highlights mismatches between the testbench generated by the Python code and the specification:

<judge_report>
{judge_report}
</judge_report>

Your task is to:

1. Think how to refine the python code to address any identified issues.
2. Provide a refined version of the Python code that addresses any identified issues.

Importance]
### 0. you must only refine the python code function body and logic, not the function interface.1. Implementing the __init__ method:
   - Initialize all internal state registers.
   - Each internal register/state variable must align with the module header in the RTL specification.
   - Explicitly initialize these states according to the RTL specification.
   - Use the exact method signature provided:
     ```python
     def __init__(self):
         '''
         Initialize all internal state registers to **zero**. It is very important and you must do this. No matter what the initial value is in the RTL specification.
         Each internal register/state variable must align with the **module header**.
         Explicitly initialize these states according to the RTL specification.
         '''
     ```

2. Implementing the load method:
   - Use the exact method signature provided:
     ```python
     def load(self, clk, stimulus_dict: Dict[str, List[str]]):
         '''
         clk: the clock signal, 1 for high, 0 for low.
         You will receive a dictionary of input variables which all all  binary string.
          Parse each input variable: You must parse each input variable and convert it from a string into its binary representation. ach internal register/state variable must align with the **module header**. eg: S = stimulus_dict['S'], S=int(S,2). Important: For subsequent unified reading and calculation, it must be binary rather than other numeral systems (or bases). It must be converted to binary; converting it to any other base—like S=int(S,16) is not allowed!!!
    Returns a dictionary of the outputs strictly aligned with the RTL module outputs name and updated states for verification. Do not return any other value like 'X', 'x' and 'd' as output!!! Also check if the output align with the FSM specification.!!!
       1. [Important] For any  problem related to the finite state machine problem, you must analyze the state transition table and write python code with the _TRUTH_TABLE dictionary (like in examples 1 and 2) to solve the problem.  To solve the FSM problem, it is necessary to analyze what states there are, which is very important: if three digits are read, there will be a total of four states (0 digits, 1 digit, 2 digits, 3 digits already received); analyze which state is entered when a 0 is read, and which state is entered when a 1 is read.
       
       return a dictionary of outputs strictly aligned with the RTL module outputs name and updated states for verification, do not return any other value like 'X', 'x' and 'd' as output! Even if the specification have random value, do not return random value as output since we can not parse them!!!!

       '''
### 1. Data structure transfer
In RTL descriptions, a signal is typically defined with a range notation like [m:n]:

The first number (m) is the leftmost position in the bit vector
The second number (n) is the rightmost position
String to Bit Position Mapping
Examine each input combination and its corresponding output position:
For descending order [m] where m > n (typical RTL):

If a signal is defined as x[4:0], then the binary value '11100' corresponds to:
x4=1 (leftmost digit in string)
x3=1
x2=1
x1=0
x0=0 (rightmost digit in string)

### 3. FSM state analysis:
  To solve the FSM problem, it is necessary to analyze what states there are, which is very important: if three digits are read, there will be a total of four states (0 digits, 1 digit, 2 digits, 3 digits already received); analyze which state is entered when a 0 is read, and which state is entered when a 1 is read.


Important notes:
- You only need to refine class GoldenDUT in the code: init and load. keep other parts of the code unchanged.
- You may only refine the init and load method body. Do not modify the method interface or return value.
- Ensure that your refinements are based on the original specification and not just the judge's report, as the report may contain errors.
- If you believe the judge's report is incorrect or irrelevant in any way, explain why in your analysis.
[Hint]

0. Perform bitwise consistency checks for all 01 sequences: Confirm input/output bit lengths match. Verify no duplicate minterms in truth tables. Cross-check Karnaugh map groupings against standard adjacency rules. When detecting non-standard ordering in inputs, check the order of outputs. 

1. Karnaugh Maps:
example:
// ab
// cd 00 01 11 10
// 00 | 1 | 0 | 1 | 1 |
// 01 | 0 | 1 | 0 | 1 |
// 11 | 1 | 1 | 0 | 0 |
// 10 | 1 | 0 | 0 | 0 |
To interpret the table:
The columns (left to right) represent the values of ab = 00, 01, 11, 10
The rows (top to bottom) represent the values of cd = 00, 01, 11, 10
Each cell contains the function output f(a, b, c, d) for the corresponding combination of a, b, c, and d.
Make sure that the key 'abcd' is constructed with: a and b from the column label (left to right: 00, 01, 11, 10), c and d from the row label (top to bottom: 00, 01, 11, 10), So the top-third cell corresponds to a=1, b=1, c=0, d=0 → '0011'
eg. For a = 1, b = 1, c = 1, d = 0, look at row cd = 10 and column ab = 11; the value is 0, so f(1, 1, 1, 0) = 0.
For a = 1, b = 0, c = 1, d = 0, look at row cd = 10 and column ab = 10; the value is 0, so f(1, 0, 1, 0) = 0. 

3. For finite state machine, the next state is determined by the current state and the input. You need to generate the truth table which includes all the possible combinations of the current state and the input. For example,    
 _TRUTH_TABLE = {{
            '0000': '1',  # S0 + w=0 → S1 → y0 = 1
            '0001': '0',  # S0 + w=1 → S2 → y0 = 0
            '0010': '1',  # S1 + w=0 → S3 → y0 = 1
            '0011': '0',  # S1 + w=1 → S4 → y0 = 0
            '0100': '0',  # S2 + w=0 → S4 → y0 = 0
            '0101': '1',  # S2 + w=1 → S5 → y0 = 1
            '0110': '1',  # S3 + w=0 → S5 → y0 = 1
            '0111': '0',  # S3 + w=1 → S0 → y0 = 0
            
            
        }}


When encountering Karnaugh maps in specifications:
-  Please construct a `_TRUTH_TABLE` dictionary representing the circuit logic, where:
   - Each key is a binary string representing the input combination, ordered using **Gray code** for Karnaugh map alignment.
   Make sure that the key 'abcd' is constructed with: a and b from the column label (left to right: 00, 01, 11, 10), c and d from the row label (top to bottom: 00, 01, 11, 10), So the top-third cell corresponds to a=1, b=1, c=0, d=0 → '0011'.

   - Each value is either 0 or 1, corresponding to the output for that input.
   - Don't-care (`d`) entries should be resolved in a way that simplifies logic (you may assign them to 0).
   - For any unspecified or ambiguous input (e.g., variables named `x` or unused in K-map), default the value to 0.
- Follow these rules strictly:
   - All input variables must be used in the Gray code order to construct the lookup key.
   - If a variable does not appear in the Karnaugh map (e.g., labeled `x` or not mentioned), treat it as `0` during simulation.
   - Only logic lookup is allowed, no procedural conditionals like `if/else` are permitted.


<refined_instruction>
{refined_instruction}
</refined_instruction>
"""
def restructured_data(file_path,new_file_path):
    with open(file_path, 'r') as f:
        json_string = f.read()
    json_data = json.loads(json_string)

    # Create a new list to store restructured data
    restructured_data = []

    # Iterate over the original JSON data
    for scenario_data in json_data:
        scenario_name = scenario_data["scenario"]
        input_vars = scenario_data["input variable"]
        output_vars = scenario_data["output variable"]
        
        # Iterate over each input variable group
        for i, input_var in enumerate(input_vars):
            # Build a new element
            new_element = {
                "scenario": f"{scenario_name}_{i}",
                "clock cycles": input_var["clock cycles"],
                "input variable": input_var,
                "output variable": output_vars[i] if i < len(output_vars) else None
            }
            
            restructured_data.append(new_element)

    # Output the restructured data
    with open(new_file_path, 'w') as f:
        json.dump(restructured_data, f, indent=2)


Instructions_for_Python_Code = """
Include the full definition of the GoldenDUT class, but only modify the body of its load method. Your code will be followed by:
'''python
def check_output(stimulus_list_scenario):

    dut = GoldenDUT()
    tb_outputs = []


    for stimulus_list in stimulus_list_scenario\["input variable"\]:


        clock_cycles = stimulus_list\['clock cycles']]
        clk = 1
        input_vars_list = {{k: v for k, v in stimulus_list.items() if k != "clock cycles"}}
        output_vars_list = {{'clock cycles':clock_cycles}}

        for i in range(clock_cycles):
            input_vars = {{k:v\[i]] for k,v in input_vars_list.items()}}

            output_vars = dut.load(clk,input_vars)
            for k,v in output_vars.items():
                if k not in output_vars_list:
                    output_vars_list\[k\] = []
                output_vars_list\[k\].append(v)
            


        tb_outputs.append(output_vars_list)

    return tb_outputs

if __name__ == "__main__":

    with open("stimulus.json", "r") as f:
        stimulus_data = json.load(f)


    if isinstance(stimulus_data, dict):
        stimulus_list_scenarios = stimulus_data.get("input variable", \[\])
    else:
        stimulus_list_scenarios = stimulus_data

    outputs=\[\]
    for stimulus_list_scenario in stimulus_list_scenarios:
        outputs.append( check_output(stimulus_list_scenario))

    print(json.dumps(outputs, indent=2))








'''
 2. Signal Loading and State Updates (load method)

Implement the method exactly as shown:

def load(self, clk, stimulus_dict: Dict[str, List[str]]):
    '''
    clk: the clock signal, 1 for high, 0 for low
    stimulus_dict: a dictionary formatted not include clock cycles as follows:
    {{"input_variable_name1": (a binary sequence string)input_variable_value1,
    "input_variable_name2": (a binary sequence string)input_variable_value2,
    "input_variable_name3": (a binary sequence string)input_variable_value3}}
    Parse each input variable and use it to perform RTL state updates.
    Please note input variable is in string format and you need to convert it to the corresponding type.
    Returns a dictionary of the outputs aligned with the RTL module outputs and updated states for verification. The format of the output dictionary is as follows:
    {{"output_variable_name1": (a binary sequence string)output_variable_value1,
    "output_variable_name2": (a binary sequence string)output_variable_value2,
    "output_variable_name3": (a binary sequence string)output_variable_value3}}
    '''
    pass  # Implement your signal update logic here


<refined_code>
[Your refined Python code here, including all the code of class GoldenDUT, but only refine the load method body]
</refined_code>

Be thorough in your analysis and clear in your explanations. Your goal is to produce a refined Python implementation that accurately reflects the functionality described in the original RTL specification.
"""
Head='''

import json
from typing import Dict, List, Union
'''

CMB_TAIL = """
def check_output(stimulus):

    dut = GoldenDUT()


        

    return dut.load(stimulus)

if __name__ == "__main__":

    with open("stimulus.json", "r") as f:
        stimulus_data = json.load(f)

    stimulus_list = []
    for stimulus in stimulus_data:
        stimulus_list.append(stimulus['input variable'])

    tb_outputs = []
    for stimulus in stimulus_list:
        scenario_outputs=[]
        for cycle in stimulus:

            outputs = check_output(cycle)
            scenario_outputs.append(outputs)
        tb_outputs.append(scenario_outputs)


    

    print(json.dumps(tb_outputs, indent=2))


"""


SEQ_TAIL='''


def check_output(stimulus_list_scenario):

    dut = GoldenDUT()
    tb_outputs = []


    for stimulus_list in stimulus_list_scenario["input variable"]:


        clock_cycles = stimulus_list['clock cycles']
        clk = 1
        input_vars_list = {k: v for k, v in stimulus_list.items() if k != "clock cycles"}
        output_vars_list = {'clock cycles':clock_cycles}
        for k,v in input_vars_list.items():
            if len(v) < clock_cycles:
                v.extend([v[-1]] * (clock_cycles - len(v)))
                
        

        for i in range(clock_cycles):
            input_vars = {k:v[i] for k,v in input_vars_list.items()}

            output_vars = dut.load(clk,input_vars)
            for k,v in output_vars.items():
                if k not in output_vars_list:
                    output_vars_list[k] = []
                output_vars_list[k].append(v)
            


        tb_outputs.append(output_vars_list)

    return tb_outputs

if __name__ == "__main__":
    stimulus_file_name = "stimulus.json"
    with open(stimulus_file_name, "r") as f:
        stimulus_data = json.load(f)


    if isinstance(stimulus_data, dict):
        stimulus_list_scenarios = stimulus_data.get("input variable", [])
    else:
        stimulus_list_scenarios = stimulus_data

    outputs=[]
    for stimulus_list_scenario in stimulus_list_scenarios:
        outputs.append( check_output(stimulus_list_scenario))
    with open(stimulus_file_name, "w") as f:
        json.dump(stimulus_list_scenarios, f, indent=4)

    print(json.dumps(outputs, indent=2))




'''

EXTRA_ORDER_PROMPT = r"""
VERY IMPORTANT: Please only include "reasoning" and "result" in your response.
Do not include any other information in your response, like 'json', 'example', 'Let me analyze','input_spec' or '<output_format>'.
Key instruction: Direct output, no extra comments.
As a reminder, please directly provide the content without adding any extra comments or explanations.
"""

EXAMPLE_OUTPUT_FORMAT = {
    "analysis": "All reasoning steps",
    
    "refined_code": "The refined Python code",
}

ACTION_OUTPUT_PROMPT = r"""
Output after running given action:
<action_output>
{action_output}
</action_output>
"""

EXAMPLE_OUTPUT = {
    "analysis": "All reasoning steps",
    
    "refined_code": "The refined Python code",
}




class RefinePythonAgent:
    def __init__(
        self,
        model: str,
        max_token: int,
        provider: str,
        cfg_path: str,
        top_p: float,
        temperature: float,
        exp_dir: str,
        task_numbers: int,
    ):
        self.model = model
        self.llm = get_llm(
            model=model,
            max_token=max_token,
            provider=provider,
            cfg_path=cfg_path,
            top_p=top_p,
            temperature=temperature,
        )
        self.token_counter = (
            TokenCounterCached(self.llm)
            if TokenCounterCached.is_cache_enabled(self.llm)
            else TokenCounter(self.llm)
        )
        self.exp_dir = exp_dir



    def get_order_prompt_messages(self) -> List[ChatMessage]:
        """Generate order prompt messages."""
        return [
            ChatMessage(
                    content=ORDER_PROMPT.format(
                        output_format="".join(
                            json.dumps(EXAMPLE_OUTPUT_FORMAT, indent=4)
                        )
                    ),
                    role=MessageRole.USER,
                ),
        ]




    def run(self,circuit_type: str,spec: str,python_code: str,judge_report: str) -> bool:
        """
        Main function to check consistency and fix implementation if needed.
        Returns True if all scenarios match after potential fixes.
        """
        """Single chat interaction to check consistency."""
        #spec, scenario, testbench = self.load_input_files()
        if isinstance(self.token_counter, TokenCounterCached):
            self.token_counter.set_enable_cache(True)
        self.token_counter.set_cur_tag(self.__class__.__name__)
        system_prompt = ChatMessage(content=SYSTEM_PROMPT, role=MessageRole.SYSTEM)

        

        init_prompt = ChatMessage(
            content=INIT_EDITION_PROMPT.format(
                specification=spec, python_code=python_code, judge_report=judge_report,refined_instruction=Instructions_for_Python_Code
            ),
            role=MessageRole.USER,
        )   
        # Generate response
        messages = [system_prompt,init_prompt] + self.get_order_prompt_messages()
        logger.info(f"Consistency checker input message: {messages}")
        resp, token_cnt = self.token_counter.count_chat(messages)
        logger.info(f"Token count: {token_cnt}")
        logger.info(f"Response: {resp.message.content}")
        

        #response_content = resp.message.content
        try:
                # output_json_obj: Dict = json.loads(response.message.content, strict=False)

                # use this for Deepseek r1 and claude-3-5-sonnet
                # if self.model == "claude-3-5-sonnet-20241022":
                #     output_json_obj: Dict = json.loads("".join(response.choices[0].message.content.split("\n")[1:]), strict=False)
                # else:
                #     output_json_obj: Dict = json.loads(response.choices[0].message.content, strict=False)
                output_json_obj: Dict = json.loads(resp.message.content, strict=False)
                python_code = Head
                python_code+='\n\n'
                python_body = output_json_obj["refined_code"]
                python_code+=output_json_obj["refined_code"]
                python_code+='\n\n'
                if circuit_type == "CMB":
                    python_code+=CMB_TAIL
                else:
                    python_code+=SEQ_TAIL
                
        except json.decoder.JSONDecodeError as e:
                    print(f"Json parse error: {e}")
                    logger.info(f"Json parse error: {e}")
                    print(resp)
                    return None
        

            # Run consistency check again with new implementation
            # Note: You might want to implement a mechanism to use the new file
            # return check_and_fix_implementation(exp_dir, token_counter)

        return python_code,python_body



args_dict = {
    # "model": "deepseek-reasoner",
    # "model": "gpt-4o-2024-08-06",
    # "model": "gpt-4o-mini-2024-07-18",
    # "model": "gemini-2.0-flash",
    # "model": "claude-3-5-sonnet-v2@20241022",
    # "model_fixer": "models/gemini-2.0-flash",
    # "model_fixer": "claude-3-5-sonnet-20241022",
    # "model_fixer": "gpt-4o-2024-08-06",
    # "provider": "anthropic",
    # "provider": "openai",
    # "provider_fixer": "anthropic",
    # "provider_fixer": "openai",
    "temperature": 0,
    "top_p": 1,
    "temperature_sample": 0.3,
    "top_p_sample": 0.95,
    "max_token": 8096,
    "model": "claude-3-5-sonnet-20241022",
    # "model_fixer": "gpt-4o-2024-08-06",
    # "provider": "anthropic",
    #"provider": "openai",
    "provider": "anthropic",
    # "model": "claude-3-7-sonnet@20250219",
    #"model": "claude-3-5-sonnet-v2@20241022",
    #"provider": "vertexanthropic",
    "provider_fixer": "vertexanthropic",
    # "task_numbers": [50],
    "task_numbers": [2, 22, 82,109, 121, 140],
    "circuit_type": "CMB",
    # "filter_instance": "Prob051|Prob052|Prob053|Prob054|Prob055|Prob101|Prob102|Prob103|Prob104|Prob105",
    # "filter_instance": "Prob092",
    # "filter_instance": "",
    "folder_path": "../verilog-eval/HDLBits/HDLBits_data_backup0304.jsonl",
    "run_identifier": "mismatch_report_for_correctness",
    "key_cfg_path": "../key.cfg",
    "use_golden_ref": True,
    "max_trials": 5,
    "exp_dir": "output_tb_gen_tb_20250406"
}



def main():
    # Example usage
    
    args = argparse.Namespace(**args_dict)
    Config(args.key_cfg_path)
    switch_log_to_file()
    timestamp = datetime.now().strftime("%Y%m%d")
    output_dir = f"{args.run_identifier}_{timestamp}"
    log_dir = f"log_{args.run_identifier}_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(log_dir, exist_ok=True)
    results=[]
    correct_cases=[ 55, 56]
    not_identify_mistake=[]
    wrong_identify_correct_cases=[]
    summary_txt= ""
   
    for task_number in args.task_numbers:
        if args.circuit_type == "CMB":
            consistency_checker = ConsistencyChecker_cmb(args.model, args.max_token, args.provider, args.key_cfg_path, args.top_p, args.temperature, args.exp_dir,task_number)
        else:
            consistency_checker = ConsistencyChecker(args.model, args.max_token, args.provider, args.key_cfg_path, args.top_p, args.temperature, args.exp_dir,task_number)

        set_log_dir(log_dir)
        for i in range(args.max_trials):
            if consistency_checker.run()==0:
                break
            else:
                    
            
                refine_python_agent = RefinePythonAgent(args.model, args.max_token, args.provider, args.key_cfg_path, args.top_p, args.temperature, args.exp_dir, task_number)
                refined_python_code = refine_python_agent.run(i,args.circuit_type)

                    # subproc_call(f"cd {output_dir_per_task}", timeout=120)
                    # subproc_call(f"cd {output_dir_per_task}", timeout=120)
                
                output_results=py.python_call_and_save(
                        f"{args.exp_dir}/{task_number}/refined_code.py", silent=True, timeout=120)

                # Merge results from the list into a string
                try:
                    output_str = "\n".join(str(result) for result in output_results)
                    output_file_path = os.path.join(args.exp_dir, f"{task_number}/refined_output.txt")
                    with open(output_file_path, "w") as output_file:
                        output_file.write(output_str)
                    if args.circuit_type == "CMB":
                        create_testbench_json_cmb(f"{args.exp_dir}/{task_number}/stimulus.json",f"{args.exp_dir}/{task_number}/refined_output.txt",f"{args.exp_dir}/{task_number}/testbench.json")
                    else:
                        create_testbench_json(f"{args.exp_dir}/{task_number}/stimulus.json",f"{args.exp_dir}/{task_number}/refined_output.txt",f"{args.exp_dir}/{task_number}/testbench.json")
                except Exception as e:
                    logger.error(f"Error writing output file: {e}")
                    logger.error(f"Output results: {output_results}")
             
    


    

if __name__ == "__main__":
    main()